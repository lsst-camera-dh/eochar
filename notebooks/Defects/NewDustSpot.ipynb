{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Notebook : NewDustSpot\n",
    "\n",
    "Goal :  This Notebook is used to identify new dust spots that appeared on sensor since vendor data \n",
    "\n",
    "Author : P.Antilogus \n",
    "\n",
    "Version : 7th July 2019 21:00 \n",
    "\n",
    "- It uses superfats at 500 nm taken at various steps of the raft-focal plane construction , and looks for new attenuated pixels.\n",
    "- The different deffects/attenuated pixels are linked by a simple but robust topological algo to build a \"dust spot\" in 2D .\n",
    "- A vignet associated to each dust spot is ploted with its absolute location on sensor and with an information of its assocaited extinction . \n",
    "- by default only spots with one pixel wit a transmission bellow 0.95 are listed . \n",
    "\n",
    "Remarks :\n",
    "- The usual way to use this script is to search for new dust spots compared to sensor vendor data . Only new dust spots , not present in vendor\n",
    "   data, can be identified/ploted. Still some coating defect intensity are highlt dependent of the light source, and may appear as new dust   spot , even if already present in vendor data.\n",
    "- A few sensor defect also appear as false positive , futher cleaning are certainly possible . \n",
    "- we could easily provide a 2D raft image with all new dust spots , to allow a direct visual inspection / comparison with the raft . A first step in this direction has been to produce a pickel file with all the information associated to each dust spot , furhter developement on the content of this pickel file could allow to prepare nice summary display. (see last boxes of this notebook)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import astropy.io.fits as pyfits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration : \n",
    " - a list of raft(s) has to be provided  ==> raft_list \n",
    " - select the # data set \"function\" ==> data_id (see in following box for config ) : \n",
    "     - select the image to be used for reference ( will look for new dusts compared to this dataset) , default : vendor data\n",
    "     - select the image to look for new dust , default TS3 data ( but last acquire raft data should be a good option ) \n",
    "     - there is 2 other set of data used for complementory information (raft data taken in # condition ) \n",
    "     - example :\n",
    "         - data_id=[0,1,2,3] : reference data = vendor, look for new dust = TS3 data , auxilary data ( for plots only ) = 2 (RTM BNL ) and 3 ( RTM SLAC ) \n",
    "         - data_id=[0,3,1,2] : reference data = vendor, look for new dust = SLAC RTM , auxilary data ( for plots only ) = 1 (TS3 data if any) and 2  (RTM BNL )\n",
    "         - after CCD cleaning we could use \"new raft\" as a reference and looks for dust in \"old raft\" to see how many were removed ... To see how many are left , we do the usual comparison with vendor data. \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION FOR THE CURRENT EXECUTION  ========================================\n",
    "# ---- raft and associated run ============ To be updated if needed \n",
    "# if no run are given (=*) , the last run taken will be used \n",
    "raft_list=[{'RTM':'RTM-004','Dust1_lab':'BNL','Dust1_run':'*','Dust2_lab':'SLAC','Dust2_run':'10141'}]\n",
    "#raft_list=[{'RTM':'RTM-012','Dust1_lab':'SLAC','Dust1_run':'11062','Dust2_lab':'SLAC','Dust2_run':'11067'}]\n",
    "# ---- configuration for the dust search and visualisation \n",
    "# data set id , define a number (0,1,2,3) associated to a type of data , this is fixed for ever  \n",
    "# 0 = 'Vendor'\n",
    "# 1 = 'TS3'\n",
    "# 2 = 'Dust1'\n",
    "# 3 = 'Dust2'  \n",
    "# then in data_id we select the # dataset for reference , dust search and comparison :\n",
    "# for example : data_id=[0,2,1,3] corresponds to :\n",
    "#                 0 ==> the reference (=minimal dust) , is from vendor data \n",
    "#                 2 ==> the data where we are looking for dust  (= in general last data set ) , here is Dust1 data as specificed in raft_list\n",
    "#                 1 ==> intermediate data set , is from TS3 \n",
    "#                 3 ==> the other intermediate data set is from Dust2 data as specificed in raft_list \n",
    "data_id=[0,2,1,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =!set | grep  .ncsa.illinois.edu | wc\n",
    "if int(count[0].split()[0])> 1 : \n",
    "    NCSA=True\n",
    "else : \n",
    "    NCSA=False\n",
    "if NCSA : \n",
    "    SLACmirror='/project/rgruendl/SLACmirror'\n",
    "    # the list of super flat for a raft - run : BNL_RAFT_ROOT+raft+'/'+run+'/cte_raft/*/*/'+'Sxx'+'/*_superflat_high.fits' \n",
    "    BNL_RAFT_ROOT=SLACmirror+'/BNLmirror/mirror/BNL-prod/prod/LCA-11021_RTM/LCA-11021_'\n",
    "    #\n",
    "    #SLAC_RAFT_ROOT=SLACmirror+'/SLACgpfs/jh_archive/LCA-11021_RTM/LCA-11021_'\n",
    "    #\n",
    "    # the list of TS3 BNL superflat for a CCD will be BNL_TS3_ROOT +CCD_NAME+'/*/cte*/v0/*/'+CCD_NAME+'_superflat_high.fits'\n",
    "    BNL_TS3_ROOT=SLACmirror+'/BNLmirror/mirror/BNL-prod/prod/*-CCD/'\n",
    "    #\n",
    "    # the list of TS3 vendor super flat for a CCD will be VENDOR_ROOT +CCD_NAME+'/*/cte*/v0/*/'+CCD_NAME+'_superflat_high.fits'\n",
    "    VENDOR_ROOT=SLACmirror+'/jobHarness/jh_archive/*-CCD/'\n",
    "    #\n",
    "    SLAC_RAFT_ROOT=SLACmirror+'/fs3/jh_archive/LCA-11021_RTM/LCA-11021_'\n",
    "else :\n",
    "    # the list of super flat for a raft - run : BNL_RAFT_ROOT+raft+'/'+run+'/cte_raft/*/*/'+'Sxx'+'/*_superflat_high.fits' \n",
    "    BNL_RAFT_ROOT='/nfs/farm/g/lsst/u1/mirror/BNL-prod/prod/LCA-11021_RTM/LCA-11021_'\n",
    "    #\n",
    "    SLAC_RAFT_ROOT='/gpfs/slac/lsst/fs1/g/data/jobHarness/jh_archive/LCA-11021_RTM/LCA-11021_'\n",
    "    #\n",
    "    # the list of TS3 BNL superflat for a CCD will be BNL_TS3_ROOT +CCD_NAME+'/*/cte*/v0/*/'+CCD_NAME+'_superflat_high.fits'\n",
    "    BNL_TS3_ROOT='/nfs/farm/g/lsst/u1/mirror/BNL-prod/prod/*-CCD/'\n",
    "    #\n",
    "    # the list of TS3 vendor super flat for a CCD will be VENDOR_ROOT +CCD_NAME+'/*/cte*/v0/*/'+CCD_NAME+'_superflat_high.fits'\n",
    "    VENDOR_ROOT='/nfs/farm/g/lsst/u1/jobHarness/jh_archive/*-CCD/'\n",
    "    #\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following box contain a set of subroutines that makes this notbook self consistent ( no outside software needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_image(image) :\n",
    "    # extract the overscan location to be used in python table  from the DATASEC keyword\n",
    "    r=image[1].header['DATASEC'][1:-1].split(',')\n",
    "    x=r[0].split(':')\n",
    "    y=r[1].split(':')\n",
    "    return int(x[0])-1,int(x[1]),int(y[0])-1,int(y[1])\n",
    "#\n",
    "def cor_image(image_fits,label='',print_run=True,plot=False) :\n",
    "    # This routine with overscan 2D  correct the image , and normalize to the median flux \n",
    "    # input : image = 2D fits image ,  plot : flag to do the control plots  \n",
    "    # print('process superflat ',image_fits)\n",
    "    # Number of line and column droped at the start and end of image to compute the normalisation of the image \n",
    "    drop=25\n",
    "    # open it\n",
    "    image=pyfits.open(image_fits)\n",
    "    # do we print information on file \n",
    "    if print_run : \n",
    "        try : \n",
    "            date_obs=image[0].header['DATE-OBS']\n",
    "        except :\n",
    "            date_obs='unknown'\n",
    "        try : \n",
    "            run=image[0].header['RUNNUM']\n",
    "        except :\n",
    "            run='unknown'\n",
    "        print(label,' date of observation= ',date_obs,' run= ',run)\n",
    "    # image shape \n",
    "    start_col,end_col,start_line,end_line=size_image(image)\n",
    "    ny,nx=np.shape(image[1].data)\n",
    "    im_cor=np.zeros((16,ny,nx))\n",
    "    # offset to get to an overscan pixel not distrubed by image area : 2 pixels should do most of the job \n",
    "    offset=2\n",
    "    #  first oversca pixel considred to compute bias \n",
    "    last_col=end_col+offset\n",
    "    #\n",
    "    last_line=end_line+offset\n",
    "    #\n",
    "    for im in range(1,17) :\n",
    "        im0=im-1\n",
    "        # correction : remark we are not taking a median ( not precise enough) ...so we can have issue \n",
    "        # due to deffect in particular in the // direction ( bleeding line ...)  ==> action \n",
    "        # correction per column to the average correction at serial overscan\n",
    "        col_cor=image[im].data[last_line:,:].mean(axis=0)-image[im].data[last_line:,last_col:].mean()\n",
    "        # correction per line function of the overscan\n",
    "        line_cor=image[im].data[:,last_col:].mean(axis=1)\n",
    "        # immage corrected \n",
    "        for i in range(ny) :\n",
    "            im_cor[im0,i,:]=image[im].data[i,:]-line_cor[i]\n",
    "        for j in range(nx):\n",
    "            im_cor[im0,:,j]-=col_cor[j]\n",
    "        # nomralize to the <flux>\n",
    "        ref=np.median(im_cor[im0,drop:-drop,drop:-drop])\n",
    "        im_cor[im0,:,:]=im_cor[im0,:,:]/ref\n",
    "        if plot : \n",
    "            fig=plt.figure(figsize=[10,10])\n",
    "            fig.suptitle(im)\n",
    "            ax = fig.add_subplot(2,3,1)\n",
    "            plt.plot(im_cor[im0,start_line:end_line,start_col:end_col].mean(axis=0))\n",
    "            ax = fig.add_subplot(2,3,4)\n",
    "            plt.plot(im_cor[im0,start_line:end_line,start_col:end_col].mean(axis=1))\n",
    "            ax = fig.add_subplot(2,3,2)\n",
    "            plt.plot(im_cor[im0,last_line:,start_col:end_col].mean(axis=0))\n",
    "            ax = fig.add_subplot(2,3,5)\n",
    "            plt.plot(im_cor[im0,end_line:,last_col:].mean(axis=1))\n",
    "            ax = fig.add_subplot(2,3,3)\n",
    "            plt.plot(col_cor[:])\n",
    "            ax = fig.add_subplot(2,3,6)\n",
    "            plt.plot(line_cor[:])\n",
    "\n",
    "            plt.show()\n",
    "    return im_cor[:,start_line:end_line,start_col:end_col]\n",
    "#\n",
    "def found_and_plot_dust_spot(ccd,data_ref,data_dust,data_ext1,data_ext2,label,cut=0.15,line_cut=3):\n",
    "    # data_ref  :   image of reference , we will look for new dust since data_ref , in general it's vendor data\n",
    "    # data_dust :   image used to look for new dust \n",
    "    # data_extra1 and data_extra2 :\" the area associated to the detected dust will be also ploted for these images\n",
    "    # cut       :   in case of dipole  in the dust image 0.15 should be used , else 0.05 ? \n",
    "    # cut_line  : number of line at start and end of image not considere for dust ( edge effect + bad data = lots of fake )\n",
    "    spot_list=np.zeros((16),dtype=np.object_)\n",
    "    dust_image=np.zeros((16),dtype=np.object_)\n",
    "    # \n",
    "    # image size in y and x \n",
    "    ylen=len(data_ref[0,:,0])\n",
    "    xlen=len(data_ref[0,0,:])\n",
    "    # Loop on amplifier\n",
    "    for im in range(16) :\n",
    "        #\n",
    "        dif_im=data_ref[im,:,:]-data_dust[im,:,:]\n",
    "        #\n",
    "        print(\"=================================================================================================\")\n",
    "        print('Summary for amplifier ',im+1,' for ccd ',ccd)\n",
    "        print('')\n",
    "        #\n",
    "        # the \"line_cut\" first and last line(s) should be droped due to edge effect associated probably to voltage \n",
    "        dust=np.array([(i,j) for i in range(line_cut,ylen-line_cut) for j in range(xlen) if dif_im[i,j]>cut],dtype=int)\n",
    "        print('we found ',len(dust),' occulted pixels in dusty image (',label[1],') not present in reference (',label[0],')')\n",
    "        print('')\n",
    "        print('')\n",
    "        spot_list[im]=[]\n",
    "        dust_image[im]=[]\n",
    "        spot_coordinate=[]\n",
    "        defect_list=np.zeros((2))\n",
    "        if len(dust)>0 :\n",
    "            # look for dust : topological agreagation : along line and then along column \n",
    "            min_dust=dust[0]\n",
    "            dust_start=0\n",
    "            nb_dust=len(dust)\n",
    "            #\n",
    "            for idust in range(1,nb_dust) :\n",
    "                dust_cur=dust[idust]\n",
    "                if dust_cur[0]>min_dust[0]+1 :\n",
    "                    # end of topological same or line+1 connection \n",
    "                    # look for topological connection along column , so first re-order the dust in function of\n",
    "                    # the column first , line second ....\n",
    "                    dust_index=np.lexsort((dust[dust_start:idust,0],dust[dust_start:idust,1]))\n",
    "                    #\n",
    "                    xmin=dust[dust_start+dust_index[0]][1]\n",
    "                    ymin=dust[dust_start+dust_index[0]][0]\n",
    "                    xmax=xmin\n",
    "                    ymax=ymin\n",
    "                    minc_dust=dust[dust_start+dust_index[0]]\n",
    "                    size=1\n",
    "                    transp=data_dust[im,ymin,xmin]\n",
    "                    for jdust in range(1,len(dust_index)) :\n",
    "                        dustc_cur=dust[dust_index[jdust]+dust_start]\n",
    "                        if dustc_cur[1]>minc_dust[1]+1 :\n",
    "                            spot_coordinate.append([ymin,ymax,xmin,xmax,size,transp/size])\n",
    "                            xmin=dustc_cur[1]\n",
    "                            ymin=dustc_cur[0]\n",
    "                            xmax=xmin\n",
    "                            ymax=ymin\n",
    "                            size=1\n",
    "                            transp=data_dust[im,dustc_cur[0],dustc_cur[1]]\n",
    "                        else :\n",
    "                            xmin=min(dustc_cur[1],xmin)\n",
    "                            ymin=min(dustc_cur[0],ymin)\n",
    "                            xmax=max(dustc_cur[1],xmax)\n",
    "                            ymax=max(dustc_cur[0],ymax) \n",
    "                            size+=1\n",
    "                            transp+=data_dust[im,dustc_cur[0],dustc_cur[1]]\n",
    "                        minc_dust=dustc_cur\n",
    "                    # save the last dust \n",
    "                    spot_coordinate.append([ymin,ymax,xmin,xmax,size,transp/size])\n",
    "                    # and the new dust index\n",
    "                    dust_start=idust\n",
    "                # \n",
    "                min_dust=dust_cur\n",
    "            # idem for the last dust\n",
    "            # the column first , line second ....\n",
    "            dust_index=np.lexsort((dust[dust_start:nb_dust,0],dust[dust_start:nb_dust,1]))\n",
    "            #\n",
    "            xmin=dust[dust_start+dust_index[0]][1]\n",
    "            ymin=dust[dust_start+dust_index[0]][0]\n",
    "            xmax=xmin\n",
    "            ymax=ymin\n",
    "            minc_dust=dust[dust_start+dust_index[0]]\n",
    "            size=1\n",
    "            transp=data_dust[im,ymin,xmin]\n",
    "            for jdust in range(1,len(dust_index)) :\n",
    "                dustc_cur=dust[dust_index[jdust]+dust_start]\n",
    "                if dustc_cur[1]>minc_dust[1]+1 :\n",
    "                    spot_coordinate.append([ymin,ymax,xmin,xmax,size,transp/size])\n",
    "                    xmin=dustc_cur[1]\n",
    "                    ymin=dustc_cur[0]\n",
    "                    xmax=xmin\n",
    "                    ymax=ymin\n",
    "                    size=1\n",
    "                    transp=data_dust[im,dustc_cur[0],dustc_cur[1]]\n",
    "                else :\n",
    "                    xmin=min(dustc_cur[1],xmin)\n",
    "                    ymin=min(dustc_cur[0],ymin)\n",
    "                    xmax=max(dustc_cur[1],xmax)\n",
    "                    ymax=max(dustc_cur[0],ymax) \n",
    "                    size+=1\n",
    "                    transp+=data_dust[im,dustc_cur[0],dustc_cur[1]]\n",
    "                minc_dust=dustc_cur\n",
    "            # save the last dust \n",
    "            spot_coordinate.append([ymin,ymax,xmin,xmax,size,transp/size])\n",
    "            #  loop on identified dust spot  \n",
    "            for cur_spot in spot_coordinate :\n",
    "                xmin=max(0,cur_spot[2]-10)\n",
    "                xmax=min(xlen,cur_spot[3]+10)\n",
    "                ymin=max(0,cur_spot[0]-10)\n",
    "                ymax=min(ylen,cur_spot[1]+10)\n",
    "                transparency=np.min(data_dust[im,cur_spot[0]:cur_spot[1]+1,cur_spot[2]:cur_spot[3]+1])\n",
    "                # Spot selection : ask for a transparency less than 0.95 for the min transparency and for a positive transparency \n",
    "                if transparency<0 or transparency>0.95 : continue\n",
    "                fig=plt.figure(figsize=[15,5])\n",
    "                spot_list[im].append(cur_spot)\n",
    "                dust_image[im].append([ymin,xmin,data_dust[im,ymin:ymax,xmin:xmax]])\n",
    "                if transparency < .6 :\n",
    "                            defect_list[1]+=1\n",
    "                else :\n",
    "                            defect_list[0]+=1\n",
    "                xlabel='ampli %d dust x=%d:%d y=%d:%d minimun transparency(new TS3)=%4.2f ' % (im+1, xmin+1,xmax+1,ymin+1,ymax+1,transparency)\n",
    "                #fig.suptitle(xlabel)\n",
    "                ax = fig.add_subplot(1,4,1)\n",
    "                ax.set_title('ref='+label[0])\n",
    "                vmin=min(np.min(data_ref[im,ymin:ymax,xmin:xmax]),np.min(data_dust[im,ymin:ymax,xmin:xmax]))\n",
    "                vmax=min(np.max(data_ref[im,ymin:ymax,xmin:xmax]),np.max(data_dust[im,ymin:ymax,xmin:xmax]))\n",
    "                plt.imshow(data_ref[im,ymin:ymax,xmin:xmax],extent=[xmin,xmax,ymin,ymax],vmin=vmin,vmax=vmax)\n",
    "                if len(data_ext1) > 0  :\n",
    "                    ax = fig.add_subplot(1,4,2)\n",
    "                    ax.set_title(label[2])\n",
    "                    plt.imshow(data_ext1[im,ymin:ymax,xmin:xmax],extent=[xmin,xmax,ymin,ymax],vmin=vmin,vmax=vmax)\n",
    "                if len(data_ext2) > 0  :\n",
    "                    ax = fig.add_subplot(1,4,3)\n",
    "                    ax.set_title(label[3])\n",
    "                    plt.imshow(data_ext2[im,ymin:ymax,xmin:xmax],extent=[xmin,xmax,ymin,ymax],vmin=vmin,vmax=vmax)\n",
    "                ax = fig.add_subplot(1,4,4)\n",
    "                ax.set_title('New Dust='+label[1])\n",
    "                plt.imshow(data_dust[im,ymin:ymax,xmin:xmax],extent=[xmin,xmax,ymin,ymax],vmin=vmin,vmax=vmax)\n",
    "                plt.show()\n",
    "                print(xlabel)\n",
    "                print(\" \")\n",
    "            print('')\n",
    "            print('Summary amplifier ',im+1,' number of light default(s) (trans>0.6)',defect_list[0],' number of strong default(s)  (trans<0.6)',defect_list[1])\n",
    "            print('For each dust spot : nb pixels & <occultation> ==> ', spot_list[im])\n",
    "            print('')\n",
    "            print('')\n",
    "    #\n",
    "    number=0\n",
    "    ocult=0.\n",
    "    nb_spot=0\n",
    "    for im in range(16) : \n",
    "        for spot in spot_list[im] :\n",
    "            nb_spot+=1\n",
    "            number+=spot[4]\n",
    "            ocult+=spot[5]*spot[4]\n",
    "    print (' ')\n",
    "    print ('ccd = ',ccd,', nb total dust spots ',nb_spot,' for a total of ',number,' pixels below thershold (occultation: .9-.85 ) with a  <transparency> =%4.2f' % (ocult/number))\n",
    "    print (' ')\n",
    "    return (spot_list,dust_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following box , does the job :\n",
    "   - it loops on the # raft , identify the sensor included in the raft and collect TS3 and vendor data for it \n",
    "   - for each sensor it loops on its amplifiers and look for new \"dust spots\" and provide a set of information and a plot for each dust spots . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "for raft in raft_list : \n",
    "    # automated initialisation from configuration box \n",
    "    label_ref=['Vendor','TS3',raft['Dust1_lab']+'('+raft['Dust1_run']+')',raft['Dust2_lab']+'('+raft['Dust2_run']+')']\n",
    "    data_sel=np.zeros((4),dtype=int)\n",
    "    label=[]\n",
    "    for i in range(4):\n",
    "        label.append(label_ref[data_id[i]])\n",
    "        data_sel[data_id[i]]=i\n",
    "    print(\"=================================================================================================\")\n",
    "    print(\"=================================================================================================\")\n",
    "    print('Processing of raft : ',raft)\n",
    "    # get BNL_raft_run \n",
    "    if raft['Dust1_lab']=='BNL' :\n",
    "        rtm_bnl=glob.glob(BNL_RAFT_ROOT+raft['RTM']+'/'+raft['Dust1_run']+'/cte_raft/*/*/S*/*_superflat_high.fits')\n",
    "    else :\n",
    "        rtm_bnl=glob.glob(SLAC_RAFT_ROOT+raft['RTM']+'/'+raft['Dust1_run']+'/cte_raft/*/*/S*/*_superflat_high.fits')\n",
    "    rtm_bnl.sort()\n",
    "    # get SLAC_raft_run \n",
    "    if raft['Dust2_lab']=='BNL' :\n",
    "        rtm_slac=glob.glob(BNL_RAFT_ROOT+raft['RTM']+'/'+raft['Dust2_run']+'/cte_raft/*/*/S*/*_superflat_high.fits')\n",
    "    else :\n",
    "        rtm_slac=glob.glob(SLAC_RAFT_ROOT+raft['RTM']+'/'+raft['Dust2_run']+'/cte_raft/*/*/S*/*_superflat_high.fits')\n",
    "    rtm_slac.sort()\n",
    "    # extract the CCD list for this raft \n",
    "    ccd_list=[]\n",
    "    ts3_list=[]\n",
    "    vendor_list=[]\n",
    "    run=0\n",
    "    # as all raft have been tested at BNL we can get the sensor list from there ... May be issue in this \n",
    "    # logic after the last re-furbisshing where some new CCD have been put in raft ... \n",
    "    if len(rtm_slac)==0 :\n",
    "        rtm_for_sensor=rtm_bnl\n",
    "    else :\n",
    "        rtm_for_sensor=rtm_slac\n",
    "    for superflat in rtm_for_sensor[-9:] :\n",
    "        tree=superflat.split('/')\n",
    "        if run != 0 and run != tree[-6] :\n",
    "            print ('Error : # run found for what should be a single raft run ',run,'#',tree[-6],'(all ccd superflats:',rtm_bn[-9:],')')\n",
    "            raise \n",
    "        else : \n",
    "            run=tree[-6]\n",
    "        ccd_list.append(tree[-1][:-20])\n",
    "    #\n",
    "    spot_all=[]\n",
    "    # get ts3 and vendor data for these CCD\n",
    "    for ccd in ccd_list : \n",
    "        dir=BNL_TS3_ROOT+'/'+ccd+'/*/cte/*/*/'+ccd+'_superflat_high.fits'\n",
    "        ts3=glob.glob(BNL_TS3_ROOT+'/'+ccd+'/*/cte/*/*/'+ccd+'_superflat_high.fits')\n",
    "        ts3.sort()\n",
    "        ts3_list.append(ts3)\n",
    "        vendor=glob.glob(VENDOR_ROOT+'/'+ccd+'/*/cte_offline/*/*/'+ccd+'_superflat_high.fits')\n",
    "        if len(vendor)==0 : vendor=glob.glob(VENDOR_ROOT+'/'+ccd+'/cte_offline/*/*/'+ccd+'_superflat_high.fits')\n",
    "        vendor.sort()\n",
    "        vendor_list.append(vendor)\n",
    "    #\n",
    "    im_dust=np.zeros((4),dtype=np.object_)\n",
    "    #\n",
    "    for iccd in range(len(ccd_list)) :\n",
    "        print(\"=================================================================================================\")\n",
    "        print('Processing of ccd : ',ccd_list[iccd])\n",
    "        # overscan correct the image \n",
    "        if len(rtm_bnl)>0 :\n",
    "            im_dust[data_sel[2]]=cor_image(rtm_bnl[-9+iccd],label[data_sel[2]])\n",
    "        elif data_id[0]==2 or data_id[1]==2 :\n",
    "            print('No Raft BNL data data for ',ccd_list[iccd],'???? Software bug , this is not possible')\n",
    "            break\n",
    "        else : \n",
    "            im_dust[data_sel[2]]=[]\n",
    "        if len(rtm_slac)>0 :\n",
    "            im_dust[data_sel[3]]=cor_image(rtm_slac[-9+iccd],label[data_sel[3]])\n",
    "        elif data_id[0]==3 or data_id[1]==3 :\n",
    "            print('No Raft SLAC data data for ',ccd_list[iccd])\n",
    "            continue\n",
    "        else : \n",
    "            im_dust[data_sel[3]]=[]\n",
    "        if len(ts3_list[iccd])>0 :\n",
    "            im_dust[data_sel[1]]=cor_image(ts3_list[iccd][-1],label[data_sel[1]])\n",
    "        elif data_id[0]==1 or data_id[1]==1 :\n",
    "            print('No TS3 BNL data data for ',ccd_list[iccd])\n",
    "            continue\n",
    "        else :\n",
    "            im_dust[data_sel[1]]=[]\n",
    "        if len(vendor_list[iccd])>0 :\n",
    "            im_dust[data_sel[0]]=cor_image(vendor_list[iccd][-1],label[data_sel[0]])\n",
    "        elif data_id[0]==0 or data_id[1]==0 :\n",
    "            print('No vendor data for ',ccd_list[iccd],'???? this should not be possible ')\n",
    "            break\n",
    "        else :\n",
    "            im_dust[data_sel[0]]=[]\n",
    "        # look for dust \n",
    "        spot_all.append((ccd_list[iccd],found_and_plot_dust_spot(ccd_list[iccd],im_dust[0],im_dust[1],im_dust[2],im_dust[3],label,cut=0.15)))\n",
    "# save the spots for a future usage\n",
    "# dump in a pickle file\n",
    "    pname=\"dust_spot_%s.pkl\" % (raft['RTM'])\n",
    "    # open\n",
    "    pfile=open(pname,'wb')\n",
    "    pickle.dump(spot_all,pfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======== Example on how to read the pickle file produced with all the identified spots ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pname=\"dust_spot_%s.pkl\" % (raft['RTM'])\n",
    "# open\n",
    "pfile=open(pname,'rb')\n",
    "all_spot=pickle.load(pfile) \n",
    "# loop on sensor\n",
    "for spot_ccd in all_spot :\n",
    "    # name of the ccd\n",
    "    ccd_name=spot_ccd[0]\n",
    "    # spot_list summary for each spot\n",
    "    spot_list=spot_ccd[1][0]\n",
    "    # normalized image from the \"ref\" +/-10 pixels arround the spot \n",
    "    dust_image=spot_ccd[1][1]\n",
    "    print('CCD=',ccd_name)\n",
    "    for i in range(16):\n",
    "        # loop on amplifier for this CCD\n",
    "        print('Amplifier=',i)\n",
    "        nb_spot=len(spot_list[i])\n",
    "        for j in range(nb_spot) :\n",
    "            spot_cur=spot_list[i][j]\n",
    "            ymin_image=dust_image[i][j][0]\n",
    "            xmin_image=dust_image[i][j][1]\n",
    "            image=dust_image[i][j][2]\n",
    "            print('ymin,ymax,xmin,xmax,nb_pixel below treshold,mean tranparency =',  spot_cur,'ymin,xmin image,len_image',ymin_image,xmin_image,len(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
